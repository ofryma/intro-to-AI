{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework #2\n",
        "This task deals with the KNN method"
      ],
      "metadata": {
        "id": "c8FdHxz_E0ob"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "d-njQyQiEy_K"
      },
      "outputs": [],
      "source": [
        "# Various libraries used in this exercise\n",
        "\n",
        "import math\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import numpy as np\n",
        "import operator\n",
        "\n",
        "# importing the hamming and euclidean distance functions\n",
        "from scipy.spatial.distance import hamming , euclidean\n",
        "\n",
        "# also found a function for calculating manhattan distance\n",
        "def manhattan(p, q):\n",
        "    \"\"\" \n",
        "    Return the manhattan distance between points p and q\n",
        "    assuming both to have the same number of dimensions\n",
        "    \"\"\"\n",
        "    # sum of absolute difference between coordinates\n",
        "    distance = 0\n",
        "    for p_i,q_i in zip(p,q):\n",
        "        distance += abs(p_i - q_i)\n",
        "    return distance\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Warmup Exercise tasks:\n",
        "\n",
        "1. Importing the relevant data from a CSV file\n",
        " * printing the first two vectors in the file\n",
        " * printing the Euclidean between the two vectors\n",
        "2. Classification of the data into the data vectors and the tags\n",
        "3. Classify a new vector of data according to the **KNN Algorithm**\n",
        " * the vector to classify in this case is [0,0,100], but we are going to write a generic function for that. the function should be able to:\n",
        "  1. take a dataset, distance calculation method, k nearest neighbours and a vecotor to classify.\n",
        "  2. calculate the distance (in a selected distance calculation method - Euclidean, Hamming or Manhattan)\n",
        "  3. create a list of distances for every vector in the dataset and sort them by the distance. every distance should be linked its related tag.\n",
        "  4. choose the first k elements in the list and finding the majority of them. according to the majority, the classification of the given vector will be printed.\n",
        "\n",
        " * print a generic form of message for the classifiction of the vector. it will also be very smart if this function will return if the prediction was correct or not (for later use in this homework)\n",
        "  1. check for k=1, k=3 for every different distance calculation methods. (6 checks total)\n"
      ],
      "metadata": {
        "id": "JYuo7xOPFfi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# warmup code\n",
        "\n",
        "def get_csv_data(url : str , n = 0 ):\n",
        "  \"\"\"\n",
        "  This function use a url for csv file, reads the data\n",
        "  and returns the data and the target vectors\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(url,  header=0 , error_bad_lines=False ) \n",
        "  #put data in dataset without header line\n",
        "  dataset = np.array(df)\n",
        "  data = []\n",
        "  target = []\n",
        "\n",
        "  for i in range(n):\n",
        "    print(dataset[i])\n",
        "\n",
        "  for p in dataset:\n",
        "    data.append(p[0:-1])\n",
        "    target.append(p[-1])\n",
        "  \n",
        "\n",
        "  return data , target\n",
        "\n",
        "\n",
        "# creating a basic class for saving the distance for every point\n",
        "# in the data while saving the related tag (target) value \n",
        "class myDist():\n",
        "  def __init__(self , dist  : int , tag : str):\n",
        "    self.dist = dist\n",
        "    self.tag = tag\n",
        "\n"
      ],
      "metadata": {
        "id": "yMuoN4pJJBpg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets try and implement the basic KNN algorithm with the next function:"
      ],
      "metadata": {
        "id": "T-RO5WuvJKz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def my_classify( data , target , point , k = 1  , dist_calc_method = \"e\"):\n",
        "  \"\"\"\n",
        "  This function classify an unknown point based on three methods of calculation:\n",
        "  1. euclidean\n",
        "  2. manhattan\n",
        "  3. hamming\n",
        "\n",
        "  The function takes a data metrix, target vector, point vector with the same\n",
        "  length the lists in the data and try to predict the tag for the given point\n",
        "  \"\"\"\n",
        "  \n",
        "\n",
        "  results = {}\n",
        "  cls_list = []\n",
        "  method = dist_calc_method\n",
        "\n",
        "  if method == \"e\":\n",
        "    the_method = \"euclidean\"\n",
        "  if method == \"m\":\n",
        "    the_method = \"manhattan\"\n",
        "  if method == \"h\":\n",
        "    the_method = \"hamming\"\n",
        "\n",
        "  ###################################\n",
        "  # calculating the distances\n",
        "  for d , t in zip(data,target):\n",
        "    if method == \"e\":\n",
        "      dist = euclidean(d , point)\n",
        "    elif method == \"m\":\n",
        "      dist = manhattan(d , point)\n",
        "    elif method == \"h\":\n",
        "      dist = hamming(d , point)\n",
        "    else:\n",
        "      dist = euclidean(d , point)\n",
        "    \n",
        "    cls_list.append(myDist(dist , t))\n",
        "    results[t] = 0\n",
        "  \n",
        "  ###################################\n",
        "  # sorting the list\n",
        "  cls_list.sort(key=operator.attrgetter('dist'))\n",
        "\n",
        "  # calculate the number of each target for classifing the unknown point's target\n",
        "  for i in range(k):\n",
        "    cur_my_dist = cls_list[i]\n",
        "    try:\n",
        "      # print(f\"{i+1}. {cls_list[i].dist} , {cls_list[i].tag}\")\n",
        "      results[cur_my_dist.tag] += 1\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  m = max(results.values())\n",
        "  index = list(results.values()).index(m)\n",
        "  prediction = list(results.keys())[index]\n",
        "\n",
        "  return prediction , the_method\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oQtPIQhUJy-d"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this basic implementation we are using all the functions from above with the small dataset from the csv file:"
      ],
      "metadata": {
        "id": "GhJ8KbszJbx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#### Basic Implementation ####\n",
        "\n",
        "url = 'https://github.com/rosenfa/ai/blob/master/myFile.csv?raw=true'\n",
        "X , y = get_csv_data(url , 2)\n",
        "\n",
        "# print the distance between the first two vectors\n",
        "print(euclidean(X[0] , X[1]))\n",
        "\n",
        "print(\"*\"*80)\n",
        "new_point = [0,0,100]\n",
        "\n",
        "methods = [\"e\" , \"m\" , \"h\"] # running the algorithm for every distance calculation method\n",
        "ks = [1,3] # and classifing of new_point for two different k\n",
        "\n",
        "for mt in methods:\n",
        "  for k in ks:\n",
        "  \n",
        "    print(\"\\n\")\n",
        "    prd , used_method = my_classify(X , y , new_point , k = k , dist_calc_method = mt)\n",
        "    print(f\"The point prediction is: {prd}, ( k : {k} , distance calculation method : {used_method} \")\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wpZra4CJq96",
        "outputId": "c406a7a3-2ca5-4c66-fe5f-c66abcd0bf07"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 'F']\n",
            "[1 5 6 'F']\n",
            "5.744562646538029\n",
            "********************************************************************************\n",
            "\n",
            "\n",
            "The point prediction is: M, ( k : 1 , distance calculation method : euclidean \n",
            "\n",
            "\n",
            "The point prediction is: M, ( k : 3 , distance calculation method : euclidean \n",
            "\n",
            "\n",
            "The point prediction is: M, ( k : 1 , distance calculation method : manhattan \n",
            "\n",
            "\n",
            "The point prediction is: F, ( k : 3 , distance calculation method : manhattan \n",
            "\n",
            "\n",
            "The point prediction is: F, ( k : 1 , distance calculation method : hamming \n",
            "\n",
            "\n",
            "The point prediction is: F, ( k : 3 , distance calculation method : hamming \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-6b16300a9471>:4: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  X , y = get_csv_data(url , 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the warmup functions on larger datasets\n",
        "Now we are going to apply the functions we wrote for the small dataset to a bit larger datasets with the next steps:\n",
        "\n",
        "1. devide the the [train set](https://github.com/rosenfa/ai/blob/master/mytrain.csv?raw=true) and [test set](https://github.com/rosenfa/ai/blob/master/mytest.csv?raw=true) to data and target (X_train , X_test and y_train , y_test).\n",
        "2. now, we will have to check each vector in the test set against the train set. using the function from the warmup section. we will count the **number of times we were right** in our predictions against the **number of times we tried**. The division between them will give us the **accuracy** percentage of our model. this section will print a generic print something like:\n",
        "```\n",
        "For k=3 (nn), using Hamming distance, the accuracy is: 0.34\n",
        "```\n",
        "3. implament this for k=1, k=7, k=15.\n",
        "Once we will be done, you should have a total of 9 different results(k=1,7,15 for E,H,M distances)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JxyoXRwVJ2D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_model(train_data , train_tags , test_data , test_tags , knn = 3 ,clac_method = \"e\"):\n",
        "  \"\"\"\n",
        "  This function use a train and test datasets, and for a given k and calculation method [e,m,h]\n",
        "  finding a predicted tag for each point in the test data set. It counts the number of correct\n",
        "  predictions and returns the accuracy of the model and the distance calculation method used\n",
        "  \"\"\"\n",
        "\n",
        "  correct = 0\n",
        "  tries = 0\n",
        "\n",
        "\n",
        "  for point , tag in zip(test_data , test_tags):\n",
        "    # using the function from the warmup section\n",
        "    prd , used = my_classify(train_data , train_tags , point , k=knn , dist_calc_method=clac_method)\n",
        "\n",
        "    #calculate the accuracy - checking for a correct prediction\n",
        "    if prd == tag:\n",
        "      correct += 1\n",
        "    tries +=1\n",
        "  \n",
        "\n",
        "  ac = correct / tries\n",
        "  return ac , used\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gDA9ADYzOdJb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can use the `knn_model()` funciton from above with the given train and test csv files:"
      ],
      "metadata": {
        "id": "GspBTRO_Le7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_url = \"https://raw.githubusercontent.com/rosenfa/ai/master/mytrain.csv\"\n",
        "test_url = \"https://github.com/rosenfa/ai/blob/master/mytest.csv?raw=true\"\n",
        "\n",
        "# spliting the data with the first function we wrote\n",
        "X_train , y_train = get_csv_data(train_url)\n",
        "X_test , y_test = get_csv_data(test_url)\n",
        "\n",
        "# checking for every calculation method with three k\n",
        "methods = [\"e\" , \"m\" , \"h\"]\n",
        "knns = [1,7,15]\n",
        "\n",
        "\n",
        "for mt in methods:\n",
        "  for knn in knns:\n",
        "    acc , used_method = knn_model(X_train , y_train , X_test , y_test , knn=knn , clac_method =mt)\n",
        "    print(f\"For k={knn}, using {used_method} distance, the accuracy is: {round(acc , 3)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6rUiSmsLjXn",
        "outputId": "90225308-2a0b-449a-b83d-675f1da6a20b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-fd054c997ece>:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  X_train , y_train = get_csv_data(train_url)\n",
            "<ipython-input-28-fd054c997ece>:6: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  X_test , y_test = get_csv_data(test_url)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For k=1, using euclidean distance, the accuracy is: 0.5\n",
            "For k=7, using euclidean distance, the accuracy is: 0.74\n",
            "For k=15, using euclidean distance, the accuracy is: 0.7\n",
            "For k=1, using manhattan distance, the accuracy is: 0.61\n",
            "For k=7, using manhattan distance, the accuracy is: 0.63\n",
            "For k=15, using manhattan distance, the accuracy is: 0.69\n",
            "For k=1, using hamming distance, the accuracy is: 0.61\n",
            "For k=7, using hamming distance, the accuracy is: 0.55\n",
            "For k=15, using hamming distance, the accuracy is: 0.57\n"
          ]
        }
      ]
    }
  ]
}