{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCTCGDLSsDP-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEhd-OKDnHBD"
      },
      "outputs": [],
      "source": [
        "# !wget --no-check-certificate \\\n",
        "#     https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "#     -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "\n",
        "# import os\n",
        "# import shutil\n",
        "# import zipfile\n",
        "\n",
        "# local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "# zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "# zip_ref.extractall('/tmp')\n",
        "# zip_ref.close()\n",
        "\n",
        "# # changing the name of the validation folder to test\n",
        "# os.rename(src=os.path.join(\"/tmp\" , \"cats_and_dogs_filtered\" , \"validation\") , dst=os.path.join(\"/tmp\" , \"cats_and_dogs_filtered\" , \"test\"))\n",
        "# filterd_dir_path = os.path.join(\"/tmp\" , \"cats_and_dogs_filtered\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FYD8-sJ_kH0J"
      },
      "outputs": [],
      "source": [
        "from re import A\n",
        "import os\n",
        "import zipfile\n",
        "from shutil import copy , rmtree\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "from keras.utils import load_img , img_to_array\n",
        "from keras import layers\n",
        "from keras import Model\n",
        "from keras.optimizers import RMSprop , SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import random\n",
        "from keras.applications import VGG16\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "class ModelUse():\n",
        "        def __init__(\n",
        "                self,\n",
        "                prediction_keys : list, # list of the tags this model know\n",
        "                filtered_dir : str,\n",
        "                data_src_dir : str = None, # source directory of the image data files\n",
        "                 # destination directory of the image files\n",
        "                train_split_size : int = None, # how many image going to the train data\n",
        "                rearange_data : bool = True, # use only for the first time to transfer from the source to the destination dirs\n",
        "                image_input_shape = (150,150,3),\n",
        "                target_size = (150,150),\n",
        "                output_activation : str = 'softmax',\n",
        "                show_logs : bool = True, # manage the logs along the way\n",
        "                use_padding : str = \"valid\",\n",
        "                use_strides = (1,1),\n",
        "\n",
        "                use_aug : bool = False,\n",
        "                rotation_range : float = 30,\n",
        "                width_shift_range : float =0.2,\n",
        "                height_shift_range : float =0.2,\n",
        "                zoom_range : float =0.2,\n",
        "                horizontal_flip : bool = True,\n",
        "\n",
        "\n",
        "                # neural network settings\n",
        "                k_size : int = 3,\n",
        "                conv2_act_func : list = [\"relu\" , \"relu\" , \"relu\"],\n",
        "                conv2_node_number : list = [16 , 32 , 64],\n",
        "\n",
        "\n",
        "                use_dropout : bool = False, # decide if you want to add dropout layer\n",
        "                dropout_rate : float = 0.5, # if there is a dropout layer, decide the dropout rate\n",
        "\n",
        "                optimizer = None, # the funciton that get send to the compile of the model\n",
        "                learning_rate : float = 0.001,\n",
        "                loss_function : any = 'binary_crossentropy',\n",
        "                train_batch_size : int = 20,\n",
        "                test_batch_size : int = 20,\n",
        "                image_class_mode : str = 'categorical',\n",
        "                existing_model_path = None, # is there is a model in a .h5 file, we can load it instead of creating NN again\n",
        "                epoch_number : int = 10, \n",
        "                verbose : int = 2, # logs of the apoch proccess\n",
        "\n",
        "                model_name : str = \"my_model\", # the name of the new modle that saved ( my_model.h5 )\n",
        "                \n",
        "                create_cnn : bool = True,\n",
        "                create_vgg : bool = True,\n",
        "\n",
        "                \n",
        "        ):\n",
        "                \n",
        "                try:\n",
        "                        self.existing_model_path = os.path.join(os.getcwd() , existing_model_path)\n",
        "                except:\n",
        "                        self.existing_model_path = None\n",
        "                self.rearange_data = rearange_data\n",
        "                prediction_keys.sort()\n",
        "                self.prediction_keys = prediction_keys\n",
        "                self.data_dict = {}\n",
        "                for key in self.prediction_keys:\n",
        "                        self.data_dict[key] = []\n",
        "                self.image_input_shape = image_input_shape\n",
        "                self.output_activation = output_activation\n",
        "                self.show_log = show_logs\n",
        "                self.use_padding = use_padding\n",
        "                self.use_strides = use_strides \n",
        "\n",
        "                self.use_aug = use_aug\n",
        "                self.rotation_range = rotation_range \n",
        "                self.width_shift_range = width_shift_range\n",
        "                self.height_shift_range = height_shift_range\n",
        "                self.zoom_range = zoom_range\n",
        "                self.horizontal_flip = horizontal_flip\n",
        "\n",
        "\n",
        "                self.k_size = k_size\n",
        "                self.conv2_act_function = conv2_act_func\n",
        "                self.conv2_node_number = conv2_node_number\n",
        "\n",
        "                self.use_dropout = use_dropout\n",
        "                self.dropout_rate = dropout_rate\n",
        "\n",
        "                self.learning_rate = learning_rate\n",
        "                if optimizer == None:\n",
        "                        self.use_optimizer = RMSprop(learning_rate=learning_rate)\n",
        "                else:\n",
        "                        self.use_optimizer = optimizer\n",
        "                self.loss_function = loss_function\n",
        "                self.epoch_number = epoch_number\n",
        "                self.data_src_dir = data_src_dir\n",
        "                self.filtered_dir = filtered_dir\n",
        "                self.train_split_size = train_split_size\n",
        "                self.image_target_size = target_size # i.e. 150X150 (150,150)\n",
        "                self.train_batch_size = train_batch_size\n",
        "                self.test_batch_size = test_batch_size\n",
        "                self.image_class_mode = image_class_mode\n",
        "                self.verbose = verbose\n",
        "\n",
        "                if create_cnn:\n",
        "                  self.model_name = model_name\n",
        "                  self.model = self.cnn_model()\n",
        "\n",
        "                if create_vgg:\n",
        "                  try:\n",
        "                          self.vgg_tl_model = self.vgg16_transfer_learning_model()\n",
        "                  except Exception as e:\n",
        "                          print(\"Something went wrong with building the vgg model\" , e) \n",
        "\n",
        "\n",
        "        def create_image_gens(self , rescale_factor = 1./255 , datagen_mean : any = False , target_size = False):\n",
        "\n",
        "                train_dir = os.path.join(self.filtered_dir , \"train\")\n",
        "                test_dir = os.path.join(self.filtered_dir , \"test\")\n",
        "\n",
        "                if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
        "                        return\n",
        "\n",
        "\n",
        "                # All images will be rescaled by 1./255\n",
        "                if self.use_aug:\n",
        "                  train_datagen = ImageDataGenerator(rescale=rescale_factor,\n",
        "                                                     rotation_range=self.rotation_range,\n",
        "                                                      width_shift_range=self.width_shift_range,\n",
        "                                                      height_shift_range=self.height_shift_range,\n",
        "                                                      zoom_range=self.zoom_range,\n",
        "                                                      horizontal_flip=self.horizontal_flip)\n",
        "                  \n",
        "                  test_datagen = ImageDataGenerator(rescale=rescale_factor)\n",
        "\n",
        "                else:\n",
        "                  train_datagen = ImageDataGenerator(rescale=rescale_factor)\n",
        "                  test_datagen = ImageDataGenerator(rescale=rescale_factor)\n",
        "\n",
        "\n",
        "                if datagen_mean:\n",
        "                        train_datagen.mean = datagen_mean\n",
        "                        test_datagen.mean = datagen_mean\n",
        "\n",
        "\n",
        "\n",
        "                  \n",
        "                if target_size:\n",
        "                  # Flow training images in batches of 20 using train_datagen generator\n",
        "                  train_gen = train_datagen.flow_from_directory(\n",
        "                          train_dir,  # This is the source directory for training images\n",
        "                          target_size=target_size,  # All images will be resized to 150x150\n",
        "                          batch_size=self.train_batch_size,\n",
        "                          class_mode=self.image_class_mode\n",
        "                          )\n",
        "\n",
        "\n",
        "                  # Flow validation images in batches of 20 using val_datagen generator\n",
        "                  test_gen = test_datagen.flow_from_directory(\n",
        "                          test_dir,\n",
        "                          target_size=target_size,\n",
        "                          batch_size=self.test_batch_size,\n",
        "                          class_mode=self.image_class_mode\n",
        "                          )\n",
        "\n",
        "                else:\n",
        "                  # Flow training images in batches of 20 using train_datagen generator\n",
        "                  train_gen = train_datagen.flow_from_directory(\n",
        "                          train_dir,  # This is the source directory for training images\n",
        "                          target_size=self.image_target_size,  # All images will be resized to 150x150\n",
        "                          batch_size=self.train_batch_size,\n",
        "                          class_mode=self.image_class_mode\n",
        "                          )\n",
        "\n",
        "\n",
        "                  # Flow validation images in batches of 20 using val_datagen generator\n",
        "                  test_gen = test_datagen.flow_from_directory(\n",
        "                          test_dir,\n",
        "                          target_size=self.image_target_size,\n",
        "                          batch_size=self.test_batch_size,\n",
        "                          class_mode=self.image_class_mode\n",
        "                          )\n",
        "\n",
        "                return train_gen , test_gen\n",
        "\n",
        "        def genarate_model(self):\n",
        "                \"\"\"\n",
        "                  This method define the NN structure\n",
        "                \"\"\" \n",
        "                # Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for\n",
        "                # the three color channels: R, G, and B\n",
        "                img_input = layers.Input(shape=self.image_input_shape)\n",
        "\n",
        "                first = True\n",
        "                # This loop use two lists of values to create the layers in this model\n",
        "                # in a dynamic way, by adding Conv2D layer and MaxPool layer according to \n",
        "                # current activation function and number of nodes given in the lists\n",
        "                for act_func , node_number in zip(self.conv2_act_function , self.conv2_node_number):\n",
        "                        if first:        \n",
        "                                x = layers.Conv2D(node_number, self.k_size, activation=act_func , padding = self.use_padding)(img_input)\n",
        "                                first = False\n",
        "                        else:\n",
        "                                x = layers.Conv2D(node_number, self.k_size, activation=act_func)(x)                \n",
        "                        x = layers.MaxPooling2D(2)(x)\n",
        "                        \n",
        "\n",
        "                # Flatten feature map to a 1-dim tensor so we can add fully connected layers\n",
        "                x = layers.Flatten()(x)\n",
        "\n",
        "                # Create a fully connected layer with ReLU activation and 512 hidden units\n",
        "                x = layers.Dense(512, activation='relu')(x)\n",
        "\n",
        "                if self.use_dropout:\n",
        "                        x = layers.Dropout(self.dropout_rate)(x)\n",
        "                \n",
        "                \n",
        "                if self.output_activation == \"sigmoid\":\n",
        "                        output_lenght = 1\n",
        "                elif self.output_activation == \"softmax\":\n",
        "                        output_lenght = len(self.prediction_keys)\n",
        "                \n",
        "                output = layers.Dense(output_lenght , activation=self.output_activation)(x)\n",
        "\n",
        "                # Create model:\n",
        "                # input = input feature map\n",
        "                # output = input feature map + stacked convolution/maxpooling layers + fully \n",
        "                # connected layer + sigmoid output layer\n",
        "                model = Model(img_input, output)\n",
        "\n",
        "                if self.show_log:\n",
        "                        model.summary()\n",
        "\n",
        "                model.compile(loss=self.loss_function ,optimizer=self.use_optimizer , metrics=['acc'])\n",
        "\n",
        "                self.model = model\n",
        "                return model\n",
        "\n",
        "        def arrange_by_tags(self):\n",
        "        \n",
        "                if os.path.exists(self.filtered_dir):\n",
        "                        rmtree(self.filtered_dir)\n",
        "\n",
        "                os.mkdir(self.filtered_dir)\n",
        "                os.mkdir(os.path.join(self.filtered_dir , \"train\"))\n",
        "                os.mkdir(os.path.join(self.filtered_dir , \"test\"))\n",
        "                \n",
        "\n",
        "                img_file_list = os.listdir(self.data_src_dir)\n",
        "\n",
        "                for img in img_file_list:\n",
        "                        for key in list(self.data_dict.keys()):\n",
        "                                if key in img:\n",
        "                                        self.data_dict[key].append(img)\n",
        "\n",
        "\n",
        "                train_images = {}\n",
        "                test_images = {}\n",
        "\n",
        "                if self.train_split_size == None:\n",
        "                        # half of the size of the min length\n",
        "                        length_of_data_list = [len(self.data_dict[key]) for key in list(self.data_dict.keys())]\n",
        "                        self.train_split_size = round(min(length_of_data_list)/2)\n",
        "\n",
        "\n",
        "\n",
        "                for key in list(self.data_dict.keys()):\n",
        "                        train_images[key] = self.data_dict[key][:self.train_split_size]\n",
        "                        test_images[key] = self.data_dict[key][self.train_split_size:]\n",
        "\n",
        "\n",
        "                # copy the files from the source dir to the filtered dir\n",
        "                for key in list(train_images.keys()):\n",
        "\n",
        "                        # copy all the train files from the source dir to the filtered dir\n",
        "                        for filename in train_images[key]:\n",
        "\n",
        "                                if not os.path.exists(f\"{self.filtered_dir}\\\\train\\\\{key}\"):\n",
        "                                        path = os.path.join(f\"{self.filtered_dir}\\\\train\", key)\n",
        "                                        \n",
        "                                        os.mkdir(path)\n",
        "\n",
        "                                copy(f\"{self.data_src_dir}\\\\{filename}\" , f\"{self.filtered_dir}\\\\train\\\\{key}\\\\{filename}\")\n",
        "                        \n",
        "                        # copy all the test files from the source dir to the filtered dir\n",
        "                        for filename in test_images[key]:\n",
        "                                if not os.path.exists(f\"{self.filtered_dir}/test/{key}\"):\n",
        "                                        os.mkdir(f\"{self.filtered_dir}/test/{key}\")\n",
        "\n",
        "                                copy(f\"{self.data_src_dir}/{filename}\" , f\"{self.filtered_dir}/test/{key}/{filename}\")\n",
        "\n",
        "                # print the length of all the files for a certain tag\n",
        "                if self.show_log:\n",
        "                        for key in list(self.data_dict.keys()):\n",
        "                                print(f\"list length of {key} : \" , len(self.data_dict[key]))\n",
        "                 \n",
        "        def predict_image_with_cnn(self ,  img_path  , model = None ):\n",
        "\n",
        "                if model==None:\n",
        "                        model = self.model\n",
        "                \n",
        "                img = load_img(img_path, target_size=self.image_target_size)  \n",
        "                x = img_to_array(img)  \n",
        "                x = x.reshape((1,) + x.shape)\n",
        "\n",
        "                # Rescale by 1/255\n",
        "                x /= 255\n",
        "\n",
        "                # Let's run our image through our network, thus obtaining all\n",
        "                # intermediate representations for this image.\n",
        "                successive_feature_maps = model.predict(x)\n",
        "                \n",
        "                if len(successive_feature_maps[0]) == 1:\n",
        "                  return successive_feature_maps[0]\n",
        "                \n",
        "                pred_dict = {}\n",
        "\n",
        "                for key , pred in zip(self.prediction_keys , successive_feature_maps[0]):\n",
        "                        pred_dict[key] = pred\n",
        "                \n",
        "\n",
        "                return pred_dict\n",
        "\n",
        "        def predict_image_with_vgg(self, image_path , model = None):\n",
        "                pass\n",
        "\n",
        "        def cnn_model(self): \n",
        "\n",
        "                model_filename = os.path.join(os.getcwd() , \".\".join([self.model_name , \"h5\"])) \n",
        "                if os.path.exists(model_filename):\n",
        "                        print(\"Loading model from  \" , model_filename)\n",
        "                        self.model = load_model(model_filename)\n",
        "                        return self.model\n",
        "                        \n",
        "                        \n",
        "                print(f\"Creating new model at {model_filename}...\")\n",
        "\n",
        "\n",
        "                if self.rearange_data:\n",
        "                        self.arrange_by_tags()\n",
        "\n",
        "                # dumb model\n",
        "                our_model = self.genarate_model()\n",
        "                \n",
        "                # create generators\n",
        "                train_generator , test_generator = self.create_image_gens()\n",
        "\n",
        "                # training the model\n",
        "                 \n",
        "                self.history = our_model.fit(\n",
        "                        train_generator,\n",
        "                        epochs=self.epoch_number,\n",
        "                        validation_data=test_generator,\n",
        "                        verbose=self.verbose\n",
        "                )\n",
        "\n",
        "                \n",
        "                try:\n",
        "                        print(\"Saving new model to \" , model_filename )\n",
        "                        our_model.save(model_filename)\n",
        "                        self.existing_model_path = model_filename\n",
        "                                \n",
        "                except Exception as e:\n",
        "                        print(e)\n",
        "\n",
        "        \n",
        "                self.model = our_model\n",
        "                return our_model\n",
        "                      \n",
        "        def print_model_history_data(self):\n",
        "                \n",
        "                try:\n",
        "                  # Retrieve a list of accuracy results on training and validation data\n",
        "                  # sets for each training epoch\n",
        "                  acc = self.history.history['acc']\n",
        "                  val_acc = self.history.history['val_acc']\n",
        "\n",
        "                  # Retrieve a list of list results on training and validation data\n",
        "                  # sets for each training epoch\n",
        "                  loss = self.history.history['loss']\n",
        "                  val_loss = self.history.history['val_loss']\n",
        "\n",
        "                  # Get number of epochs\n",
        "                  epochs = range(len(acc))\n",
        "\n",
        "                  # Plot training and validation accuracy per epoch\n",
        "                  plt.plot(epochs, acc)\n",
        "                  plt.plot(epochs, val_acc)\n",
        "                  plt.title('Training and validation accuracy')\n",
        "\n",
        "                  plt.figure()\n",
        "\n",
        "                  # Plot training and validation loss per epoch\n",
        "                  plt.plot(epochs, loss)\n",
        "                  plt.plot(epochs, val_loss)\n",
        "                  plt.title('Training and validation loss')\n",
        "\n",
        "                  last_apoch_acc = acc[-1]\n",
        "                  last_apoch_val_acc = val_acc[-1]\n",
        "                  return last_apoch_acc , last_apoch_val_acc\n",
        "                except:\n",
        "                  _ , test_gen = self.create_image_gens()\n",
        "                  loss , acc = self.model.evaluate(test_gen)\n",
        "                  return acc , acc \n",
        "                  \n",
        "\n",
        "        def vgg16_transfer_learning_model(self):\n",
        "\n",
        "                # load model\n",
        "                model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
        "                \n",
        "                # mark loaded layers as not trainable\n",
        "                for layer in model.layers:\n",
        "                        layer.trainable = False\n",
        "\n",
        "\n",
        "                # add new classifier layers\n",
        "                flat1 = layers.Flatten()(model.layers[-1].output)\n",
        "                class1 = layers.Dense(128, activation=self.output_activation, kernel_initializer='he_uniform')(flat1)\n",
        "                output = layers.Dense(1, activation=self.output_activation)(class1)\n",
        "                \n",
        "                # define new model\n",
        "                model = Model(inputs=model.inputs, outputs=output)\n",
        "\n",
        "                # compile model\n",
        "                model.compile(optimizer=self.use_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "                train_generator , test_generator = self.create_image_gens(datagen_mean=[123.68, 116.779, 103.939] ,target_size=(224,224))\n",
        "\n",
        "                model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=self.epoch_number, verbose=self.verbose)\n",
        "\n",
        "                self.vgg_tl_model = model\n",
        "\n",
        "                return model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JM5vK4aUpYG2"
      },
      "outputs": [],
      "source": [
        "filtered_dir_path = \"/content/drive/MyDrive/intro-to-AI/hw/data_mining_project/image_iden/weather_filtered\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VivHCdN4pkjd",
        "outputId": "81e793d0-dd24-4283-84e0-aa68df37880a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new model at /content/weather_model_20.h5...\n",
            "Found 600 images belonging to 4 classes.\n",
            "Found 375 images belonging to 4 classes.\n",
            "Saving new model to  /content/weather_model_20.h5\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 1s 0us/step\n",
            "Found 600 images belonging to 4 classes.\n",
            "Found 375 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "batch_size_list = [20,128] # ,512,1024\n",
        "max_acc = 0\n",
        "max_val_acc = 0\n",
        "best_batch_size = batch_size_list[0]\n",
        "\n",
        "best_model_name = \"\"\n",
        "\n",
        "\n",
        "for bs in batch_size_list:\n",
        " \n",
        "  weater_use = ModelUse(\n",
        "\n",
        "        # data_src_dir=os.path.join(os.getcwd() , \"hw\\data_mining_project\\image_iden\\weather\"),\n",
        "        filtered_dir=filtered_dir_path,\n",
        "        rearange_data=False,\n",
        "        prediction_keys = [\"rain\" , \"cloudy\" , \"shine\" , \"sunrise\"],\n",
        "        conv2_act_func = [\"relu\" , \"relu\" , \"relu\"],\n",
        "        conv2_node_number = [16 , 32 , 64],\n",
        "        model_name=f\"weather_model_{bs}\",\n",
        "        train_split_size=150,\n",
        "        show_logs = False,\n",
        "        output_activation=\"softmax\",\n",
        "        optimizer=SGD(learning_rate=0.001, momentum=0.9),\n",
        "        epoch_number=10,\n",
        "        verbose=0,\n",
        "        test_batch_size=bs,\n",
        "        train_batch_size=bs,\n",
        "\n",
        "        )\n",
        "  \n",
        "  cur_acc , cur_val_acc = weater_use.print_model_history_data()\n",
        "\n",
        "  if cur_val_acc > max_val_acc:\n",
        "    max_val_acc = cur_val_acc\n",
        "    best_model_name = weater_use.model_name\n",
        "    best_batch_size = bs\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDAwqoErr5zS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}